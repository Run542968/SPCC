{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "处理movielens数据\n",
    "新增了对某个item社会共识的计算\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import coo_matrix,csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "RATING_FILE_NAME = dict({'movie': 'ratings.txt', # Following MKR\n",
    "                         'Amazon_book': 'BX-Book-Ratings.csv', #Following LightGCN\n",
    "                         'music': 'user_artists.dat',\n",
    "                         'news': 'ratings.txt'})\n",
    "SEP = dict({'movie': '::', 'Amazon_book': ';', 'music': '\\t', 'news': '\\t'})\n",
    "HitRateThreshold=dict({'movie':0.2,'book':0,'music':0})\n",
    "User_Item_SampleNum=dict({'movie':3000,'book':0,'music':0})\n",
    "Item_User_SampleNum=dict({'movie':5000,'book':0,'music':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Template():\n",
    "    '''\n",
    "    Amazon book, 这是一个构造数据集所有流程的模板, 下面会分函数\n",
    "    '''\n",
    "    ## 读取Amazon Book的数据\n",
    "\n",
    "    train_user_item=dict()\n",
    "    train_item_user=dict()\n",
    "    test_user_item=dict()\n",
    "    test_item_user=dict()\n",
    "\n",
    "    file_path='./data/book/'\n",
    "    train_data=file_path+'train.txt'\n",
    "    test_data=file_path+'test.txt'\n",
    "\n",
    "    # 先把所有数据读出来\n",
    "    for line in open(train_data,encoding='utf-8').readlines():\n",
    "        datas=line.strip().split(' ')\n",
    "        user_id=int(datas[0])\n",
    "        if user_id not in train_user_item.keys():\n",
    "            train_user_item[user_id]=set()\n",
    "            \n",
    "        for data in datas[1:]:\n",
    "            item_id=int(data)\n",
    "            train_user_item[user_id].add(item_id)\n",
    "\n",
    "            if item_id not in train_item_user.keys():\n",
    "                train_item_user[item_id]=set()\n",
    "            train_item_user[item_id].add(user_id)\n",
    "\n",
    "    for line in open(test_data,encoding=\"utf-8\").readlines():\n",
    "        datas=line.strip().split(' ')\n",
    "\n",
    "        user_id=int(datas[0])\n",
    "        if user_id not in test_user_item.keys():\n",
    "            test_user_item[user_id]=set()\n",
    "            \n",
    "        for data in datas[1:]:\n",
    "            item_id=int(data)\n",
    "            test_user_item[user_id].add(item_id)\n",
    "            if item_id not in test_item_user.keys():\n",
    "                test_item_user[item_id]=set()\n",
    "            test_item_user[item_id].add(user_id)\n",
    "\n",
    "    # 统计一下有多少用户，多少物品\n",
    "    item_nums=len(train_item_user.keys())\n",
    "    user_nums=len(train_user_item.keys())\n",
    "    print(f\"user_num:{user_nums}, item_num:{item_nums}\")\n",
    "\n",
    "\n",
    "    # contruct item hit rate\n",
    "    item_hitRate=dict()\n",
    "    for item in train_item_user.keys():\n",
    "        item_hitRate[item]=len(train_item_user[item])/user_nums\n",
    "\n",
    "\n",
    "    # 判断是否每个用户都至少有一个交互\n",
    "    for user in train_user_item.keys(): \n",
    "        if len(train_user_item[user])==0:\n",
    "            print(f\"uu:{user}\")\n",
    "    for user in test_user_item.keys(): \n",
    "        if len(test_user_item[user])==0:\n",
    "            print(f\"uu:{user}\") # 发现测试集里有用户没访问item，要特殊处理 [13647,41589,50736,52234]\n",
    "\n",
    "    # 判断是否每个物品都被至少一个用户访问过: √\n",
    "    for item in train_item_user.keys(): \n",
    "        if len(train_item_user[item])==0:\n",
    "            print(f\"ii:{item}\")\n",
    "    for item in test_item_user.keys(): \n",
    "        if len(test_item_user[item])==0:\n",
    "            print(f\"ii:{item}\")\n",
    "\n",
    "    # 统计一下训练集有多少交互\n",
    "    train_interaction_num=0\n",
    "    for user in train_user_item.keys():\n",
    "        train_interaction_num+=len(train_user_item[user])\n",
    "    print(train_interaction_num)\n",
    "    print(train_interaction_num/2984108) # 看看是按照什么比例划分数据集\n",
    "\n",
    "\n",
    "    ## 使用训练集构造邻接矩阵\n",
    "    row=[]\n",
    "    col=[]\n",
    "    data=[]\n",
    "    for user_id in train_user_item.keys():\n",
    "        for item_id in train_user_item[user_id]:\n",
    "            row.append(user_id)\n",
    "            col.append(item_id+len(train_user_item))\n",
    "            data.append(1)\n",
    "    for item_id in train_item_user.keys(): \n",
    "        for user_id in train_item_user[item_id]:\n",
    "            row.append(item_id+len(train_user_item))\n",
    "            col.append(user_id)\n",
    "            data.append(1)\n",
    "\n",
    "    csr_adj_matrix=csr_matrix((data,(row,col)))\n",
    "\n",
    "\n",
    "    ## 构造训练数据\n",
    "    # # 和LightGCN稍有差别，差别在于对user的采样方式\n",
    "    # item_set=set(range(user_nums))\n",
    "    # train_data=[]\n",
    "    # for user in train_user_item.keys():\n",
    "    #     for p_item in range(len(train_user_item[user])):\n",
    "    #         n_item=np.random.choice(list(item_set-train_user_item[user]))\n",
    "    #         row_data=[user,p_item,n_item]\n",
    "    #         train_data.append(row_data)\n",
    "    # 和LightGCN完全一样\n",
    "    train_data=[]\n",
    "    users = np.random.randint(0, user_nums, train_interaction_num)\n",
    "    for user in users:\n",
    "        posForUser = list(train_user_item[user]) # 得到这个用户的所有正样本list\n",
    "        if len(posForUser) == 0: # 如果这个用户没有正样本，跳过\n",
    "            continue\n",
    "        posindex = np.random.randint(0, len(posForUser)) # 从这个用户的所有正样本随机抽一个\n",
    "        p_item = posForUser[posindex]\n",
    "        while True:\n",
    "            n_item = np.random.randint(0, item_nums) # 从所有item中随机抽一个\n",
    "            if n_item in posForUser: # 如果抽中的在正样本集中，继续抽，知道抽出一个负样本\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        train_data.append([user, p_item, n_item]) # 添加到训练集\n",
    "\n",
    "    return train_user_item,test_user_item,train_item_user,test_item_user,item_hitRate,csr_adj_matrix,train_data\n",
    "\n",
    "# # 调用方法\n",
    "# train_user_item,test_user_item,train_item_user,test_item_user,item_hitRate,csr_adj_matrix,train_data=data_Template()\n",
    "\n",
    "# ## 保存以上数据\n",
    "# DATASET='book'\n",
    "# sp.save_npz('./data/'+DATASET+'/csr_'+DATASET+'_matrix.npz',csr_adj_matrix)\n",
    "# np.save(\"./data/\"+DATASET+\"/train_user_item.npy\",train_user_item)\n",
    "# np.save(\"./data/\"+DATASET+\"/test_user_item.npy\",test_user_item)\n",
    "# np.save(\"./data/\"+DATASET+\"/item_hitRate.npy\",item_hitRate)\n",
    "\n",
    "\n",
    "# # 测一下生成的邻接矩阵和原训练集数据是否一致\n",
    "# print(csr_adj_matrix.sum(axis=1)[15])\n",
    "# print(len(train_user_item[15]))\n",
    "# print(csr_adj_matrix.sum(axis=1)[len(train_user_item)+256])\n",
    "# print(len(train_item_user[256]))\n",
    "\n",
    "\n",
    "# # 检查一下训练数据是不是正确的\n",
    "# print(train_data[9854])\n",
    "# print(432 in train_user_item[12856])\n",
    "# print(43997 in train_user_item[12856])\n",
    "# print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_construct_book():\n",
    "    \n",
    "    ## 读取Amazon Book的数据\n",
    "    train_user_item=dict()\n",
    "    train_item_user=dict()\n",
    "    test_user_item=dict()\n",
    "    test_item_user=dict()\n",
    "\n",
    "    file_path='./data/book/'\n",
    "    train_data=file_path+'train.txt'\n",
    "    test_data=file_path+'test.txt'\n",
    "\n",
    "    # 先把所有数据读出来\n",
    "    for line in open(train_data,encoding='utf-8').readlines():\n",
    "        datas=line.strip().split(' ')\n",
    "        user_id=int(datas[0])\n",
    "        if user_id not in train_user_item.keys():\n",
    "            train_user_item[user_id]=set()\n",
    "            \n",
    "        for data in datas[1:]:\n",
    "            item_id=int(data)\n",
    "            train_user_item[user_id].add(item_id)\n",
    "\n",
    "            if item_id not in train_item_user.keys():\n",
    "                train_item_user[item_id]=set()\n",
    "            train_item_user[item_id].add(user_id)\n",
    "\n",
    "    for line in open(test_data,encoding=\"utf-8\").readlines():\n",
    "        datas=line.strip().split(' ')\n",
    "\n",
    "        user_id=int(datas[0])\n",
    "        if user_id not in test_user_item.keys():\n",
    "            test_user_item[user_id]=set()\n",
    "            \n",
    "        for data in datas[1:]:\n",
    "            item_id=int(data)\n",
    "            test_user_item[user_id].add(item_id)\n",
    "            if item_id not in test_item_user.keys():\n",
    "                test_item_user[item_id]=set()\n",
    "            test_item_user[item_id].add(user_id)\n",
    "\n",
    "    # 统计一下有多少用户，多少物品\n",
    "    item_num=len(train_item_user.keys())\n",
    "    user_num=len(train_user_item.keys())\n",
    "    print(f\"user_num:{user_num}, item_num:{item_num}\")\n",
    "\n",
    "    # 判断是否每个用户都至少有一个交互\n",
    "    for user in train_user_item.keys(): \n",
    "        if len(train_user_item[user])==0:\n",
    "            print(f\"uu:{user}\")\n",
    "    for user in test_user_item.keys(): \n",
    "        if len(test_user_item[user])==0:\n",
    "            print(f\"uu:{user}\") # 发现测试集里有用户没访问item，要特殊处理 [13647,41589,50736,52234]\n",
    "\n",
    "    # 判断是否每个物品都被至少一个用户访问过: √\n",
    "    for item in train_item_user.keys(): \n",
    "        if len(train_item_user[item])==0:\n",
    "            print(f\"ii:{item}\")\n",
    "    for item in test_item_user.keys(): \n",
    "        if len(test_item_user[item])==0:\n",
    "            print(f\"ii:{item}\")\n",
    "\n",
    "    return train_user_item,train_item_user,test_user_item,test_item_user,user_num,item_num\n",
    "\n",
    "\n",
    "def dict_construct_movie(split_rate=0.8,positive_replace=False):\n",
    "    '''\n",
    "        movielens-1M\n",
    "        采样的时候按照从item的层面(实验说明这样有效)进行采样, 因为item的数量少, 所以能够保证训练集中一个物品至少被一个用户访问,一个用户至少访问一个物品\n",
    "        这样做, 对于某些只访问过一个item的用户, 它的测试集gt是空的, 所以测试集要做处理\n",
    "    '''\n",
    "    \n",
    "    item_index_old2new = dict()\n",
    "    item_index_new2old = dict()\n",
    "    user_index_old2new = dict()\n",
    "    user_index_new2old = dict()\n",
    "    user_item = dict()\n",
    "    item_user=dict()\n",
    "    \n",
    "    # 读取数据并按照从0开始，重标号\n",
    "\n",
    "    file = './data/movie/ratings.dat'\n",
    "    print('reading ratings file: ' + file + ' ...')\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for line in open(file, encoding='utf-8').readlines():\n",
    "        line_data=line.strip().split('::')\n",
    "        user_index = int(line_data[0])\n",
    "        item_index = int(line_data[1])\n",
    "        rating = int(line_data[2])\n",
    "\n",
    "        if user_index not in user_index_old2new:\n",
    "            user_index_old2new[user_index] = i\n",
    "            user_index_new2old[i]=user_index\n",
    "            i += 1\n",
    "        if item_index not in item_index_old2new:\n",
    "            item_index_old2new[item_index] = j\n",
    "            item_index_new2old[j]=item_index\n",
    "            j+=1\n",
    "\n",
    "        if rating > 0:\n",
    "            if user_index_old2new[user_index] not in user_item:\n",
    "                user_item[user_index_old2new[user_index]]=set()\n",
    "            user_item[user_index_old2new[user_index]].add(item_index_old2new[item_index])\n",
    "\n",
    "            if item_index_old2new[item_index] not in item_user:\n",
    "                item_user[item_index_old2new[item_index]]=set()\n",
    "            item_user[item_index_old2new[item_index]].add(user_index_old2new[user_index])\n",
    "        \n",
    "    # 统计数据集中用户和物品总数\n",
    "    user_num=len(user_item)\n",
    "    item_num=len(item_user)\n",
    "    print(\"The num of user is %d \" % (user_num))\n",
    "    print(\"The num of item is %d \" % (item_num))\n",
    "    \n",
    "    # 将所有交互按照0.8划分训练集和测试集\n",
    "    train_user_item=dict()\n",
    "    train_item_user=dict()\n",
    "    test_user_item=dict()\n",
    "    test_item_user=dict()\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for item in item_user.keys():\n",
    "            if not positive_replace:    # 这里使用math.ceil取上整，是为了尽量让物品被采样在训练集，对于movielens这种稀疏数据集，一个用户可能只访问过一个物品，那就把这个物品放在训练集\n",
    "                train_item_user[item]=set(np.random.choice(list(item_user[item]), size=math.ceil(split_rate*len(item_user[item])),replace=False)) #不允许重复采样，保证训练和测试的正样本是8:2，加个set()去重\n",
    "            else:\n",
    "                train_item_user[item]=set(np.random.choice(list(item_user[item]), size=math.ceil(split_rate*len(item_user[item])),replace=True))#允许重复采样，正样本可能比0.8小，加个set()去重\n",
    "            test_item_user[item]=item_user[item]-set(train_item_user[item])\n",
    "\n",
    "        train_user_set=set()\n",
    "        for item in train_item_user.keys():\n",
    "            train_user_set=train_user_set.union(train_item_user[item])\n",
    "        \n",
    "        if len(train_user_set)==user_num: # 直到训练集中出现了所有用户，停止循环\n",
    "            break\n",
    "    \n",
    "\n",
    "    # 将train_user_item转为train_item_user,用于构造adjacency graph\n",
    "    for item in train_item_user.keys():\n",
    "        for user in train_item_user[item]:\n",
    "            if user not in train_user_item.keys():\n",
    "                train_user_item[user]=set()\n",
    "            train_user_item[user].add(item)\n",
    "    # 将test_user_item转为test_item_user\n",
    "    for item in test_item_user.keys():\n",
    "        for user in test_item_user[item]:\n",
    "            if user not in test_user_item.keys():\n",
    "                test_user_item[user]=set()\n",
    "            test_user_item[user].add(item)\n",
    "\n",
    "    # 判断是否每个用户都至少有一个交互\n",
    "    for user in train_user_item.keys(): \n",
    "        if len(train_user_item[user])==0:\n",
    "            print(f\"train_user_index_new2old[user]:{user}->{user_index_new2old[user]}\")\n",
    "    for user in test_user_item.keys(): \n",
    "        if len(test_user_item[user])==0:\n",
    "            print(f\"test_user_index_new2old[user]:{user}->{user_index_new2old[user]}\") # 发现测试集里有用户没访问item，要特殊处理 [13647,41589,50736,52234]\n",
    "\n",
    "    # 判断是否每个物品都被至少一个用户访问过: √\n",
    "    for item in train_item_user.keys(): \n",
    "        if len(train_item_user[item])==0:\n",
    "            print(f\"train_item_index_new2old[item]:{item}->{item_index_new2old[item]}\")\n",
    "    for item in test_item_user.keys(): \n",
    "        if len(test_item_user[item])==0:\n",
    "            print(f\"test_item_index_new2old[item]:{item}->{item_index_new2old[item]}\")\n",
    "            \n",
    "    return train_user_item,train_item_user,test_user_item,test_item_user,user_num,item_num\n",
    "\n",
    "\n",
    "# def dict_construct_movie_v2(split_rate=0.8,positive_replace=False):\n",
    "#     '''\n",
    "#         采样的时候, 保证训练集中每个用户至少访问一个物品, 每个物品至少访问一个用户，只有这样才停止采样，否则再采一次\n",
    "#     '''\n",
    "    \n",
    "#     item_index_old2new = dict()\n",
    "#     item_index_new2old = dict()\n",
    "#     user_index_old2new = dict()\n",
    "#     user_index_new2old = dict()\n",
    "#     user_item = dict()\n",
    "#     item_user=dict()\n",
    "    \n",
    "#     # 读取数据并按照从0开始，重标号\n",
    "\n",
    "#     file = './data/movie/ratings.dat'\n",
    "#     print('reading ratings file: ' + file + ' ...')\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     for line in open(file, encoding='utf-8').readlines():\n",
    "#         line_data=line.strip().split('::')\n",
    "#         user_index = int(line_data[0])\n",
    "#         item_index = int(line_data[1])\n",
    "#         rating = int(line_data[2])\n",
    "\n",
    "#         if user_index not in user_index_old2new:\n",
    "#             user_index_old2new[user_index] = i\n",
    "#             user_index_new2old[i]=user_index\n",
    "#             i += 1\n",
    "#         if item_index not in item_index_old2new:\n",
    "#             item_index_old2new[item_index] = j\n",
    "#             item_index_new2old[j]=item_index\n",
    "#             j+=1\n",
    "\n",
    "#         if rating > 0:\n",
    "#             if user_index_old2new[user_index] not in user_item:\n",
    "#                 user_item[user_index_old2new[user_index]]=set()\n",
    "#             user_item[user_index_old2new[user_index]].add(item_index_old2new[item_index])\n",
    "\n",
    "#             if item_index_old2new[item_index] not in item_user:\n",
    "#                 item_user[item_index_old2new[item_index]]=set()\n",
    "#             item_user[item_index_old2new[item_index]].add(user_index_old2new[user_index])\n",
    "        \n",
    "#     # 统计数据集中用户和物品总数\n",
    "#     user_num=len(user_item)\n",
    "#     item_num=len(item_user)\n",
    "#     print(\"The num of user is %d \" % (user_num))\n",
    "#     print(\"The num of item is %d \" % (item_num))\n",
    "    \n",
    "#     # 将所有交互按照0.8划分训练集和测试集\n",
    "#     train_user_item=dict()\n",
    "#     train_item_user=dict()\n",
    "#     test_user_item=dict()\n",
    "#     test_item_user=dict()\n",
    "\n",
    "#     while True:\n",
    "\n",
    "#         for user in user_item.keys():\n",
    "#             if not positive_replace:\n",
    "#                 train_user_item[user]=set(np.random.choice(list(user_item[user]), size=math.ceil(split_rate*len(user_item[user])),replace=False)) #不允许重复采样，保证训练和测试的正样本是8:2，加个set()去重\n",
    "#             else:\n",
    "#                 train_user_item[user]=set(np.random.choice(list(user_item[user]), size=math.ceil(split_rate*len(user_item[user])),replace=True))#允许重复采样，正样本可能比0.8小，加个set()去重\n",
    "#             test_user_item[user]=user_item[user]-set(train_user_item[user])\n",
    "\n",
    "#         train_item_set=set()\n",
    "#         for user in train_user_item.keys():\n",
    "#             train_item_set=train_item_set.union(train_user_item[user])\n",
    "        \n",
    "#         if len(train_item_set)==item_num:\n",
    "#             break\n",
    "    \n",
    "#     # 将train_user_item转为train_item_user,用于构造adjacency graph\n",
    "#     for user in train_user_item.keys():\n",
    "#         for item in train_user_item[user]:\n",
    "#             if item not in train_item_user.keys():\n",
    "#                 train_item_user[item]=set()\n",
    "#             train_item_user[item].add(user)\n",
    "#     # 将test_user_item转为test_item_user\n",
    "#     for user in test_user_item.keys():\n",
    "#         for item in test_user_item[user]:\n",
    "#             if item not in test_item_user.keys():\n",
    "#                 test_item_user[item]=set()\n",
    "#             test_item_user[item].add(user)\n",
    "\n",
    "#     # 判断是否每个用户都至少有一个交互\n",
    "#     for user in train_user_item.keys(): \n",
    "#         if len(train_user_item[user])==0:\n",
    "#             print(f\"uu:{user}\")\n",
    "#     for user in test_user_item.keys(): \n",
    "#         if len(test_user_item[user])==0:\n",
    "#             print(f\"uu:{user}\") # 发现测试集里有用户没访问item，要特殊处理 [13647,41589,50736,52234]\n",
    "\n",
    "#     # 判断是否每个物品都被至少一个用户访问过: √\n",
    "#     for item in train_item_user.keys(): \n",
    "#         if len(train_item_user[item])==0:\n",
    "#             print(f\"ii:{item}\")\n",
    "#     for item in test_item_user.keys(): \n",
    "#         if len(test_item_user[item])==0:\n",
    "#             print(f\"ii:{item}\")\n",
    "#     return train_user_item,train_item_user,test_user_item,test_item_user,user_num,item_num\n",
    "\n",
    "# def dict_construct_movie_v3(split_rate=0.8,positive_replace=False):\n",
    "#     '''\n",
    "#         采样的时候, 保证训练集中每个用户至少访问一个物品, 每个物品至少访问一个用户，只有这样才停止采样，否则再采一次\n",
    "#         从user的层面采会不会快一点\n",
    "#     '''\n",
    "    \n",
    "#     item_index_old2new = dict()\n",
    "#     item_index_new2old = dict()\n",
    "#     user_index_old2new = dict()\n",
    "#     user_index_new2old = dict()\n",
    "#     user_item = dict()\n",
    "#     item_user=dict()\n",
    "    \n",
    "#     # 读取数据并按照从0开始，重标号\n",
    "\n",
    "#     file = './data/movie/ratings.dat'\n",
    "#     print('reading ratings file: ' + file + ' ...')\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     for line in open(file, encoding='utf-8').readlines():\n",
    "#         line_data=line.strip().split('::')\n",
    "#         user_index = int(line_data[0])\n",
    "#         item_index = int(line_data[1])\n",
    "#         rating = int(line_data[2])\n",
    "\n",
    "#         if user_index not in user_index_old2new:\n",
    "#             user_index_old2new[user_index] = i\n",
    "#             user_index_new2old[i]=user_index\n",
    "#             i += 1\n",
    "#         if item_index not in item_index_old2new:\n",
    "#             item_index_old2new[item_index] = j\n",
    "#             item_index_new2old[j]=item_index\n",
    "#             j+=1\n",
    "\n",
    "#         if rating > 0:\n",
    "#             if user_index_old2new[user_index] not in user_item:\n",
    "#                 user_item[user_index_old2new[user_index]]=set()\n",
    "#             user_item[user_index_old2new[user_index]].add(item_index_old2new[item_index])\n",
    "\n",
    "#             if item_index_old2new[item_index] not in item_user:\n",
    "#                 item_user[item_index_old2new[item_index]]=set()\n",
    "#             item_user[item_index_old2new[item_index]].add(user_index_old2new[user_index])\n",
    "        \n",
    "#     # 统计数据集中用户和物品总数\n",
    "#     user_num=len(user_item)\n",
    "#     item_num=len(item_user)\n",
    "#     print(\"The num of user is %d \" % (user_num))\n",
    "#     print(\"The num of item is %d \" % (item_num))\n",
    "    \n",
    "#     # 将所有交互按照0.8划分训练集和测试集\n",
    "#     train_user_item=dict()\n",
    "#     train_item_user=dict()\n",
    "#     test_user_item=dict()\n",
    "#     test_item_user=dict()\n",
    "\n",
    "#     while True:\n",
    "\n",
    "#         for item in item_user.keys():\n",
    "#             if not positive_replace:\n",
    "#                 train_item_user[item]=set(np.random.choice(list(item_user[item]), size=math.ceil(split_rate*len(item_user[item])),replace=False)) #不允许重复采样，保证训练和测试的正样本是8:2，加个set()去重\n",
    "#             else:\n",
    "#                 train_item_user[item]=set(np.random.choice(list(item_user[item]), size=math.ceil(split_rate*len(item_user[item])),replace=True))#允许重复采样，正样本可能比0.8小，加个set()去重\n",
    "#             test_item_user[item]=item_user[item]-set(train_item_user[item])\n",
    "\n",
    "#         train_user_set=set()\n",
    "#         for item in train_item_user.keys():\n",
    "#             train_user_set=train_user_set.union(train_item_user[item])\n",
    "        \n",
    "#         if len(train_user_set)==user_num:\n",
    "#             break\n",
    "    \n",
    "#     # 将train_user_item转为train_item_user,用于构造adjacency graph\n",
    "#     for item in train_item_user.keys():\n",
    "#         for user in train_item_user[item]:\n",
    "#             if user not in train_user_item.keys():\n",
    "#                 train_user_item[user]=set()\n",
    "#             train_user_item[user].add(item)\n",
    "#     # 将test_user_item转为test_item_user\n",
    "#     for item in test_item_user.keys():\n",
    "#         for user in test_item_user[item]:\n",
    "#             if user not in test_user_item.keys():\n",
    "#                 test_user_item[user]=set()\n",
    "#             test_user_item[user].add(item)\n",
    "\n",
    "#     # 判断是否每个用户都至少有一个交互\n",
    "#     for user in train_user_item.keys(): \n",
    "#         if len(train_user_item[user])==0:\n",
    "#             print(f\"train_user_index_new2old[user]:{user_index_new2old[user]}\")\n",
    "#     for user in test_user_item.keys(): \n",
    "#         if len(test_user_item[user])==0:\n",
    "#             print(f\"test_user_index_new2old[user]:{user_index_new2old[user]}\") # 发现测试集里有用户没访问item，要特殊处理 [13647,41589,50736,52234]\n",
    "\n",
    "#     # 判断是否每个物品都被至少一个用户访问过: √\n",
    "#     for item in train_item_user.keys(): \n",
    "#         if len(train_item_user[item])==0:\n",
    "#             print(f\"train_item_index_new2old[item]:{item_index_new2old[item]}\")\n",
    "#     for item in test_item_user.keys(): \n",
    "#         if len(test_item_user[item])==0:\n",
    "#             print(f\"test_item_index_new2old[item]:{item_index_new2old[item]}\")\n",
    "#     return train_user_item,train_item_user,test_user_item,test_item_user,user_num,item_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_sampling(train_user_item,user_num,item_num,BPR=True):\n",
    "\n",
    "    # 统计一下训练集有多少交互\n",
    "    train_interaction_num=0\n",
    "    for user in train_user_item.keys():\n",
    "        train_interaction_num+=len(train_user_item[user])\n",
    "    print(\"train_interaction_num: \",train_interaction_num)\n",
    "    \n",
    "    ## 构造训练数据\n",
    "    if BPR:\n",
    "        # # 和LightGCN稍有差别，差别在于对user的采样方式\n",
    "        # item_set=set(range(user_num))\n",
    "        # train_data=[]\n",
    "        # for user in train_user_item.keys():\n",
    "        #     for p_item in range(len(train_user_item[user])):\n",
    "        #         n_item=np.random.choice(list(item_set-train_user_item[user]))\n",
    "        #         row_data=[user,p_item,n_item]\n",
    "        #         train_data.append(row_data)\n",
    "        \n",
    "        # 和LightGCN完全一样\n",
    "        train_data=[]\n",
    "        users = np.random.randint(0, user_num, train_interaction_num) # 有多少交互就构造多少正负样本对\n",
    "        for user in users:\n",
    "            posForUser = list(train_user_item[user]) # 得到这个用户的所有正样本list\n",
    "            if len(posForUser) == 0: # 如果这个用户没有正样本，跳过\n",
    "                continue\n",
    "            posindex = np.random.randint(0, len(posForUser)) # 从这个用户的所有正样本随机抽一个\n",
    "            p_item = posForUser[posindex]\n",
    "            while True:\n",
    "                n_item = np.random.randint(0, item_num) # 从所有item中随机抽一个\n",
    "                if n_item in posForUser: # 如果抽中的在正样本集中，继续抽，直到抽出一个负样本\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            train_data.append([user, p_item, n_item]) # 添加到训练集\n",
    "    else:\n",
    "        # 和LightGCN完全一样\n",
    "        train_data=[]\n",
    "        users = np.random.randint(0, user_num, train_interaction_num) # 有多少交互就构造多少正负样本对\n",
    "        for user in users:\n",
    "            posForUser = list(train_user_item[user]) # 得到这个用户的所有正样本list\n",
    "            if len(posForUser) == 0: # 如果这个用户没有正样本，跳过\n",
    "                continue\n",
    "            posindex = np.random.randint(0, len(posForUser)) # 从这个用户的所有正样本随机抽一个\n",
    "            p_item = posForUser[posindex]\n",
    "            while True:\n",
    "                n_item = np.random.randint(0, item_num) # 从所有item中随机抽一个\n",
    "                if n_item in posForUser: # 如果抽中的在正样本集中，继续抽，直到抽出一个负样本\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            train_data.append([user,p_item,1]) # 添加到训练集\n",
    "            train_data.append([user,n_item,0])\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "def adjacent_matrix_construct(train_user_item,train_item_user):\n",
    "\n",
    "    ## 使用训练集构造邻接矩阵\n",
    "    row=[]\n",
    "    col=[]\n",
    "    data=[]\n",
    "    for user_id in train_user_item.keys():\n",
    "        for item_id in train_user_item[user_id]:\n",
    "            row.append(user_id)\n",
    "            col.append(item_id+len(train_user_item))\n",
    "            data.append(1)\n",
    "    for item_id in train_item_user.keys(): \n",
    "        for user_id in train_item_user[item_id]:\n",
    "            row.append(item_id+len(train_user_item))\n",
    "            col.append(user_id)\n",
    "            data.append(1)\n",
    "\n",
    "    csr_adj_matrix=csr_matrix((data,(row,col)))\n",
    "\n",
    "    return csr_adj_matrix\n",
    "\n",
    "def item_hitRate_construct(train_item_user,user_num):\n",
    "\n",
    "    # contruct item hit rate\n",
    "    item_hitRate=dict()\n",
    "    for item in train_item_user.keys():\n",
    "        item_hitRate[item]=len(train_item_user[item])/user_num\n",
    "    \n",
    "    return item_hitRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构造MovieLens\n",
    "DATASET='movie'\n",
    "train_user_item,train_item_user,test_user_item,test_item_user,user_num,item_num=dict_construct_movie(split_rate=0.8,positive_replace=False)\n",
    "train_data=train_data_sampling(train_user_item,user_num,item_num,BPR=True)\n",
    "csr_adj_matrix=adjacent_matrix_construct(train_user_item,train_item_user)\n",
    "item_hitRate=item_hitRate_construct(train_item_user,user_num)\n",
    "# 保存数据\n",
    "sp.save_npz('./data/'+DATASET+'/csr_'+DATASET+'_matrix.npz',csr_adj_matrix)\n",
    "np.save(\"./data/\"+DATASET+\"/train_user_item.npy\",train_user_item)\n",
    "np.save(\"./data/\"+DATASET+\"/test_user_item.npy\",test_user_item)\n",
    "np.save(\"./data/\"+DATASET+\"/item_hitRate.npy\",item_hitRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_item_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 分析hitRate的数据分布，找到合适阈值\n",
    "\n",
    "import seaborn as sns\n",
    "hitRate_list=list(item_hitRate.values())\n",
    "# sns.histplot([1 if i >=0.05 else 0 for i in hitRate_list])\n",
    "sns.histplot(item_hitRate)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09b221b0f031966922bc51733b8c6c9f4c71418990fd5205807b5c811da68d9a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('run_MKR': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
